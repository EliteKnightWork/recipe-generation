# Backend Configuration
BACKEND_PORT=8000

# Frontend Configuration
FRONTEND_PORT=3000

# API URL (for frontend to connect to backend)
API_URL=http://localhost:8000

# GPU Configuration (set to "false" to disable GPU)
USE_GPU=true

# Language Enhancement (set to "true" to enable Llama-based recipe enhancement)
# Model will be downloaded automatically on first startup
USE_LANGUAGE_ENHANCEMENT=true

# Language Model Selection
LLAMA_MODEL_NAME=TinyLlama/TinyLlama-1.1B-Chat-v1.0